{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Grabbing info from TJ's model explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "df = pd.read_csv('data/kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  2.,  0.,  3.],\n",
       "       [ 2.,  7.,  2.,  3.],\n",
       "       [ 3., 10.,  0.,  3.],\n",
       "       ...,\n",
       "       [ 1.,  1.,  2.,  3.],\n",
       "       [ 2.,  8.,  2.,  4.],\n",
       "       [ 1.,  1.,  2.,  3.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This should be all data cleaning and pre-processimg\n",
    "grade_num = []\n",
    "for index, row in df.iterrows():\n",
    "    grade_num.append(int((str(row['grade'])[0:2])))\n",
    "df['grade_num'] = grade_num\n",
    "df.drop('grade', axis = 1)\n",
    "df['sqft_living_ratio'] = df['sqft_living'] / df['sqft_living15']\n",
    "df['sqft_living_ratio'] = df['sqft_living_ratio'].loc[(np.abs(stats.zscore(df.sqft_living_ratio)) < 2)]\n",
    "df = df.dropna(subset = ['sqft_living_ratio'])\n",
    "df['sqft_lot_ratio'] = df['sqft_lot'] / df['sqft_lot15']\n",
    "df['sqft_lot_ratio'] = df['sqft_lot_ratio'].loc[(np.abs(stats.zscore(df.sqft_lot_ratio)) < 2)]\n",
    "df = df.dropna(subset = ['sqft_lot_ratio'])\n",
    "df.waterfront.fillna(value='NO', inplace = True)\n",
    "df.waterfront.replace( to_replace = ['NO','YES'], value =  [0,1], inplace = True)\n",
    "df = df[df['bedrooms'] < 33]\n",
    "df['sqft_basement'] = df['sqft_basement'].replace({'?': 0.0})\n",
    "df['sqft_basement'] = df['sqft_basement'].astype(float)\n",
    "df['view'] = df['view'].replace({'NONE': 0, 'AVERAGE': 1, 'GOOD': 2, 'FAIR': 3, 'EXCELLENT':4})\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit_transform(df[['zipcode']])\n",
    "ord_enc = OrdinalEncoder()\n",
    "ord_enc.fit_transform(df[['bedrooms','bathrooms','floors','grade_num']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df[['bedrooms', 'bathrooms', 'sqft_living',\n",
    "       'sqft_lot', 'floors', 'waterfront', 'view',\n",
    "       'sqft_above', 'sqft_basement', 'zipcode','sqft_living15', 'sqft_lot15', 'grade_num']]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,df.price)\n",
    "\n",
    "training_data = pd.concat([X_train,y_train], axis = 1)\n",
    "testing_data = pd.concat([X_test,y_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "baseline_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:      0.46703818504446115\n",
      "Validation score: 0.47794820895447865\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate, ShuffleSplit\n",
    "\n",
    "most_correlated_feature = 'sqft_living'\n",
    "\n",
    "splitter = ShuffleSplit(n_splits=3, test_size=0.25, random_state=0)\n",
    "\n",
    "baseline_scores = cross_validate(\n",
    "    estimator=baseline_model,\n",
    "    X=X_train[[most_correlated_feature]],\n",
    "    y=y_train,\n",
    "    return_train_score=True,\n",
    "    cv=splitter\n",
    ")\n",
    "\n",
    "print(\"Train score:     \", baseline_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", baseline_scores[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>y_train</td>     <th>  R-squared:         </th>  <td>   0.600</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.599</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   1754.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 16 Nov 2021</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:22:30</td>     <th>  Log-Likelihood:    </th> <td>-2.0855e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 15244</td>      <th>  AIC:               </th>  <td>4.171e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 15230</td>      <th>  BIC:               </th>  <td>4.172e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>-4.464e+07</td> <td> 3.42e+06</td> <td>  -13.058</td> <td> 0.000</td> <td>-5.13e+07</td> <td>-3.79e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train[0]</th>  <td>  -2.8e+04</td> <td> 2544.404</td> <td>  -11.004</td> <td> 0.000</td> <td> -3.3e+04</td> <td> -2.3e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train[1]</th>  <td>-1.889e+04</td> <td> 3956.699</td> <td>   -4.775</td> <td> 0.000</td> <td>-2.66e+04</td> <td>-1.11e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train[2]</th>  <td>  142.1348</td> <td>   23.521</td> <td>    6.043</td> <td> 0.000</td> <td>   96.030</td> <td>  188.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train[3]</th>  <td>    0.0038</td> <td>    0.118</td> <td>    0.033</td> <td> 0.974</td> <td>   -0.227</td> <td>    0.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train[4]</th>  <td>-9070.2909</td> <td> 4396.394</td> <td>   -2.063</td> <td> 0.039</td> <td>-1.77e+04</td> <td> -452.833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train[5]</th>  <td> 5.349e+05</td> <td>  2.4e+04</td> <td>   22.308</td> <td> 0.000</td> <td> 4.88e+05</td> <td> 5.82e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train[6]</th>  <td> 7.092e+04</td> <td> 3020.085</td> <td>   23.482</td> <td> 0.000</td> <td>  6.5e+04</td> <td> 7.68e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train[7]</th>  <td>    1.4421</td> <td>   23.383</td> <td>    0.062</td> <td> 0.951</td> <td>  -44.391</td> <td>   47.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train[8]</th>  <td>   51.3394</td> <td>   23.232</td> <td>    2.210</td> <td> 0.027</td> <td>    5.802</td> <td>   96.877</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train[9]</th>  <td>  450.0594</td> <td>   34.839</td> <td>   12.918</td> <td> 0.000</td> <td>  381.770</td> <td>  518.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train[10]</th> <td>   55.9156</td> <td>    5.045</td> <td>   11.083</td> <td> 0.000</td> <td>   46.027</td> <td>   65.804</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train[11]</th> <td>   -0.5610</td> <td>    0.137</td> <td>   -4.089</td> <td> 0.000</td> <td>   -0.830</td> <td>   -0.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train[12]</th> <td> 9.738e+04</td> <td> 2674.899</td> <td>   36.405</td> <td> 0.000</td> <td> 9.21e+04</td> <td> 1.03e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>7259.640</td> <th>  Durbin-Watson:     </th> <td>   1.987</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>95398.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.953</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>14.616</td>  <th>  Cond. No.          </th> <td>2.00e+08</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large,  2e+08. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                y_train   R-squared:                       0.600\n",
       "Model:                            OLS   Adj. R-squared:                  0.599\n",
       "Method:                 Least Squares   F-statistic:                     1754.\n",
       "Date:                Tue, 16 Nov 2021   Prob (F-statistic):               0.00\n",
       "Time:                        14:22:30   Log-Likelihood:            -2.0855e+05\n",
       "No. Observations:               15244   AIC:                         4.171e+05\n",
       "Df Residuals:                   15230   BIC:                         4.172e+05\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept   -4.464e+07   3.42e+06    -13.058      0.000   -5.13e+07   -3.79e+07\n",
       "X_train[0]    -2.8e+04   2544.404    -11.004      0.000    -3.3e+04    -2.3e+04\n",
       "X_train[1]  -1.889e+04   3956.699     -4.775      0.000   -2.66e+04   -1.11e+04\n",
       "X_train[2]    142.1348     23.521      6.043      0.000      96.030     188.239\n",
       "X_train[3]      0.0038      0.118      0.033      0.974      -0.227       0.235\n",
       "X_train[4]  -9070.2909   4396.394     -2.063      0.039   -1.77e+04    -452.833\n",
       "X_train[5]   5.349e+05    2.4e+04     22.308      0.000    4.88e+05    5.82e+05\n",
       "X_train[6]   7.092e+04   3020.085     23.482      0.000     6.5e+04    7.68e+04\n",
       "X_train[7]      1.4421     23.383      0.062      0.951     -44.391      47.275\n",
       "X_train[8]     51.3394     23.232      2.210      0.027       5.802      96.877\n",
       "X_train[9]    450.0594     34.839     12.918      0.000     381.770     518.349\n",
       "X_train[10]    55.9156      5.045     11.083      0.000      46.027      65.804\n",
       "X_train[11]    -0.5610      0.137     -4.089      0.000      -0.830      -0.292\n",
       "X_train[12]  9.738e+04   2674.899     36.405      0.000    9.21e+04    1.03e+05\n",
       "==============================================================================\n",
       "Omnibus:                     7259.640   Durbin-Watson:                   1.987\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            95398.004\n",
       "Skew:                           1.953   Prob(JB):                         0.00\n",
       "Kurtosis:                      14.616   Cond. No.                     2.00e+08\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large,  2e+08. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols('y_train ~ X_train', data = training_data).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ziplist = ohe.categories_[0].tolist()\n",
    "zipliststr = []\n",
    "for i in ziplist: \n",
    "    zipliststr.append(str(i))\n",
    "\n",
    "ohe = OneHotEncoder(sparse = False)\n",
    "ohe.fit_transform(df[['zipcode']])\n",
    "zip_encoded = ohe.fit_transform(df[['zipcode']])\n",
    "zip_enc_df = pd.DataFrame(zip_encoded, columns=ohe.categories_[0], index=df.index)\n",
    "\n",
    "\n",
    "df.drop(\"zipcode\", axis=1, inplace=True)\n",
    "df = pd.concat([df, zip_enc_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohegrade = OneHotEncoder(sparse = False)\n",
    "ohegrade.fit_transform(df[['grade']])\n",
    "grade_encoded = ohe.fit_transform(df[['grade']])\n",
    "grade_enc_df = pd.DataFrame(grade_encoded, columns=ohegrade.categories_[0], index=df.index)\n",
    "\n",
    "\n",
    "df.drop(\"grade\", axis=1, inplace=True)\n",
    "df = pd.concat([df, grade_enc_df], axis=1)\n",
    "\n",
    "\n",
    "gradelist = ohegrade.categories_[0].tolist()\n",
    "gradeliststr = []\n",
    "for i in gradelist: \n",
    "    gradeliststr.append(str(i))\n",
    "\n",
    "#ord_enc = OrdinalEncoder()\n",
    "#ord_enc.fit_transform(df[['bedrooms','bathrooms','floors','grade_num']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>10 Very Good</th>\n",
       "      <th>11 Excellent</th>\n",
       "      <th>12 Luxury</th>\n",
       "      <th>13 Mansion</th>\n",
       "      <th>4 Low</th>\n",
       "      <th>5 Fair</th>\n",
       "      <th>6 Low Average</th>\n",
       "      <th>7 Average</th>\n",
       "      <th>8 Good</th>\n",
       "      <th>9 Better</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>10/13/2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>2/18/2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7237550310</td>\n",
       "      <td>5/12/2014</td>\n",
       "      <td>1230000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5420</td>\n",
       "      <td>101930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21592</th>\n",
       "      <td>263000018</td>\n",
       "      <td>5/21/2014</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21593</th>\n",
       "      <td>6600060120</td>\n",
       "      <td>2/23/2015</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21594</th>\n",
       "      <td>1523300141</td>\n",
       "      <td>6/23/2014</td>\n",
       "      <td>402101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21595</th>\n",
       "      <td>291310100</td>\n",
       "      <td>1/16/2015</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21596</th>\n",
       "      <td>1523300157</td>\n",
       "      <td>10/15/2014</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20385 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id        date      price  bedrooms  bathrooms  sqft_living  \\\n",
       "0      7129300520  10/13/2014   221900.0         3       1.00         1180   \n",
       "1      6414100192   12/9/2014   538000.0         3       2.25         2570   \n",
       "3      2487200875   12/9/2014   604000.0         4       3.00         1960   \n",
       "4      1954400510   2/18/2015   510000.0         3       2.00         1680   \n",
       "5      7237550310   5/12/2014  1230000.0         4       4.50         5420   \n",
       "...           ...         ...        ...       ...        ...          ...   \n",
       "21592   263000018   5/21/2014   360000.0         3       2.50         1530   \n",
       "21593  6600060120   2/23/2015   400000.0         4       2.50         2310   \n",
       "21594  1523300141   6/23/2014   402101.0         2       0.75         1020   \n",
       "21595   291310100   1/16/2015   400000.0         3       2.50         1600   \n",
       "21596  1523300157  10/15/2014   325000.0         2       0.75         1020   \n",
       "\n",
       "       sqft_lot  floors  waterfront  view  ... 10 Very Good  11 Excellent  \\\n",
       "0          5650     1.0           0   0.0  ...          0.0           0.0   \n",
       "1          7242     2.0           0   0.0  ...          0.0           0.0   \n",
       "3          5000     1.0           0   0.0  ...          0.0           0.0   \n",
       "4          8080     1.0           0   0.0  ...          0.0           0.0   \n",
       "5        101930     1.0           0   0.0  ...          0.0           1.0   \n",
       "...         ...     ...         ...   ...  ...          ...           ...   \n",
       "21592      1131     3.0           0   0.0  ...          0.0           0.0   \n",
       "21593      5813     2.0           0   0.0  ...          0.0           0.0   \n",
       "21594      1350     2.0           0   0.0  ...          0.0           0.0   \n",
       "21595      2388     2.0           0   0.0  ...          0.0           0.0   \n",
       "21596      1076     2.0           0   0.0  ...          0.0           0.0   \n",
       "\n",
       "       12 Luxury  13 Mansion  4 Low  5 Fair  6 Low Average  7 Average  8 Good  \\\n",
       "0            0.0         0.0    0.0     0.0            0.0        1.0     0.0   \n",
       "1            0.0         0.0    0.0     0.0            0.0        1.0     0.0   \n",
       "3            0.0         0.0    0.0     0.0            0.0        1.0     0.0   \n",
       "4            0.0         0.0    0.0     0.0            0.0        0.0     1.0   \n",
       "5            0.0         0.0    0.0     0.0            0.0        0.0     0.0   \n",
       "...          ...         ...    ...     ...            ...        ...     ...   \n",
       "21592        0.0         0.0    0.0     0.0            0.0        0.0     1.0   \n",
       "21593        0.0         0.0    0.0     0.0            0.0        0.0     1.0   \n",
       "21594        0.0         0.0    0.0     0.0            0.0        1.0     0.0   \n",
       "21595        0.0         0.0    0.0     0.0            0.0        0.0     1.0   \n",
       "21596        0.0         0.0    0.0     0.0            0.0        1.0     0.0   \n",
       "\n",
       "       9 Better  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "3           0.0  \n",
       "4           0.0  \n",
       "5           0.0  \n",
       "...         ...  \n",
       "21592       0.0  \n",
       "21593       0.0  \n",
       "21594       0.0  \n",
       "21595       0.0  \n",
       "21596       0.0  \n",
       "\n",
       "[20385 rows x 102 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'zipcode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'zipcode'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d28b5c728540>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                     98199 ]\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdf_Seattle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'zipcode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeattle_zipcodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mdf_Outside\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'zipcode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeattle_zipcodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdf_original\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'zipcode'"
     ]
    }
   ],
   "source": [
    "Seattle_zipcodes = [98101, 98102, 98103, 98104, 98105, \n",
    "                    98106, 98107, 98108, 98109, 98112, \n",
    "                    98115, 98116, 98117, 98118, 98119, \n",
    "                    98121, 98122, 98125, 98126, 98133, \n",
    "                    98134, 98136, 98144, 98146, 98154, \n",
    "                    98164, 98174, 98177, 98178, 98195, \n",
    "                    98199 ]\n",
    "\n",
    "df_Seattle = df[df['zipcode'].isin(Seattle_zipcodes)]\n",
    "df_Outside = df[~df['zipcode'].isin(Seattle_zipcodes)]\n",
    "df_original = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse = False)\n",
    "ohe.fit_transform(df[['zipcode']])\n",
    "zip_encoded = ohe.fit_transform(df[['zipcode']])\n",
    "zip_enc_df = pd.DataFrame(zip_encoded, columns=ohe.categories_[0], index=df.index)\n",
    "df = pd.concat([df, zip_enc_df], axis=1)\n",
    "ziplist = ohe.categories_[0].tolist()\n",
    "zipliststr = []\n",
    "for i in ziplist: \n",
    "    zipliststr.append(str(i))\n",
    "zipliststr\n",
    "ord_enc = OrdinalEncoder()\n",
    "ord_enc.fit_transform(df[['bedrooms','bathrooms','floors','grade_num']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['id','date','price','lat','long','sqft_living_ratio','sqft_lot_ratio','condition','yr_built','yr_renovated','grade','zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,df.price)\n",
    "\n",
    "training_data = pd.concat([X_train,y_train], axis = 1)\n",
    "testing_data = pd.concat([X_test,y_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "baseline_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, ShuffleSplit\n",
    "\n",
    "splitter = ShuffleSplit(n_splits=3, test_size=0.25, random_state=0)\n",
    "\n",
    "baseline_scores = cross_validate(\n",
    "    estimator=baseline_model,\n",
    "    X=training_data[['sqft_living']],\n",
    "    y=training_data.price,\n",
    "    return_train_score=True,\n",
    "    cv=splitter\n",
    ")\n",
    "\n",
    "print(\"Baseline Train score:     \", baseline_scores[\"train_score\"].mean())\n",
    "print(\"Baseline Validation score:\", baseline_scores[\"test_score\"].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_model = LinearRegression()\n",
    "\n",
    "second_model_scores = cross_validate(\n",
    "    estimator=second_model,\n",
    "    X=training_data.drop(columns = 'price'),\n",
    "    y=y_train,\n",
    "    return_train_score=True,\n",
    "    cv=splitter\n",
    ")\n",
    "\n",
    "print(\"Second Model Train score:     \", second_model_scores[\"train_score\"].mean())\n",
    "print(\"Second Model Validation score:\", second_model_scores[\"test_score\"].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_for_RFECV = StandardScaler().fit_transform(X_train)\n",
    "model_for_RFECV = LinearRegression()\n",
    "\n",
    "# Instantiate and fit the selector\n",
    "selector = RFECV(model_for_RFECV, cv=splitter)\n",
    "selector.fit(X_train_for_RFECV, y_train)\n",
    "\n",
    "# Print the results\n",
    "print(\"Was the column selected?\")\n",
    "for index, col in enumerate(X_train.columns):\n",
    "    print(f\"{col}: {selector.support_[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train,y_train)\n",
    "print(linreg.score(X_train, y_train))\n",
    "print(linreg.score(X_test, y_test))\n",
    "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
    "\n",
    "y_hat_train = linreg.predict(X_train)\n",
    "y_hat_test = linreg.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_residuals = y_hat_train - y_train\n",
    "test_residuals = y_hat_test - y_test\n",
    "\n",
    "# Calculate training and test MSE\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_hat_train)\n",
    "test_mse = mean_squared_error(y_test, y_hat_test)\n",
    "print('Train Root Mean Squarred Error:', np.sqrt(train_mse))\n",
    "print('Test Root Mean Squarred Error:', np.sqrt(test_mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
